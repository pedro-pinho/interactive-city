/**
 * Copyright 2016 IBM Corp.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 **/

module.exports = function (RED) {
  const SERVICE_IDENTIFIER = 'speech-to-text';
  var pkg = require('../../package.json'),
    request = require('request'),
    cfenv = require('cfenv'),
    temp = require('temp'),
    url = require('url'),
    fs = require('fs'),
    fileType = require('file-type'),
    serviceutils = require('../../utilities/service-utils'),
    payloadutils = require('../../utilities/payload-utils'),
    sttV1 = require('watson-developer-cloud/speech-to-text/v1'),
    username = '', password = '', sUsername = '', sPassword = '',
    endpoint = '',
    sEndpoint = 'https://stream.watsonplatform.net/speech-to-text/api',
    service = serviceutils.getServiceCreds(SERVICE_IDENTIFIER);

  // Require the Cloud Foundry Module to pull credentials from bound service
  // If they are found then the username and password will be stored in
  // the variables sUsername and sPassword.
  //
  // This separation between sUsername and username is to allow
  // the end user to modify the credentials when the service is not bound.
  // Otherwise, once set credentials are never reset, resulting in a frustrated
  // user who, when he errenously enters bad credentials, can't figure out why
  // the edited ones are not being taken.

  if (service) {
    sUsername = service.username;
    sPassword = service.password;
    sEndpoint = service.url;
  }

  // temp is being used for file streaming to allow the file to arrive so it can be processed.
  temp.track();

  // These are APIs that the node has created to allow it to dynamically fetch Bluemix
  // credentials, and also translation models. This allows the node to keep up to
  // date with new tranlations, without the need for a code update of this node.

  // Node RED Admin - fetch and set vcap services
  RED.httpAdmin.get('/watson-speech-to-text/vcap', function (req, res) {
    res.json(service ? {bound_service: true} : null);
  });

  // API used by widget to fetch available models
  RED.httpAdmin.get('/watson-speech-to-text/models', function (req, res) {
    //endpoint = sEndpoint ? sEndpoint : req.query.e;
    endpoint = req.query.e ? req.query.e : sEndpoint;

    var stt = new sttV1({
      username: sUsername ? sUsername : req.query.un,
      password: sPassword ? sPassword : req.query.pwd,
      url: endpoint,
      headers: {
        'User-Agent': pkg.name + '-' + pkg.version
      }
    });

    stt.getModels({}, function(err, models){
      if (err) {
        res.json(err);
      } else {
        res.json(models);
      }
    });
  });

  // API used by widget to fetch available customisations
  RED.httpAdmin.get('/watson-speech-to-text/customs', function (req, res) {
    //endpoint = sEndpoint ? sEndpoint : req.query.e;
    endpoint = req.query.e ? req.query.e : sEndpoint;

    var stt = new sttV1({
      username: sUsername ? sUsername : req.query.un,
      password: sPassword ? sPassword : req.query.pwd,
      url: endpoint,
      headers: {
        'User-Agent': pkg.name + '-' + pkg.version
      }
    });

    stt.getCustomizations({}, function(err, customs){
      if (err) {
        res.json(err);
      } else {
        res.json(customs);
      }
    });
  });


  // This is the Speech to Text Node

  function Node (config) {
    RED.nodes.createNode(this, config);
    var node = this;

    function initialCheck(username, password) {
      if (!username || !password) {
        return Promise.reject('Missing Speech To Text service credentials');
      }
      return Promise.resolve();
    }

    function configCheck() {
      var message = '';

      if (!config.lang) {
        message = 'Missing audio language configuration, unable to process speech.';
      } else if (!config.band) {
        message = 'Missing audio quality configuration, unable to process speech.';
      }

      if (message) {
        return Promise.reject(message);
      }
      return Promise.resolve();
    }

    function payloadCheck(msg) {
      var message = '';
      // The input comes in on msg.payload, and can either be an audio file or a string
      // representing a URL.
      if (!msg.payload instanceof Buffer || !typeof msg.payload === 'string') {
        message = 'Invalid property: msg.payload, can only be a URL or a Buffer.';
      } else if (!(msg.payload instanceof Buffer)) {
        // This check is repeated just before the call to the service, but
        // its also performed here as a double check.
        if (typeof msg.payload === 'string' && !payloadutils.urlCheck(msg.payload)) {
          message = 'Invalid URL.';
        }
      } else {
        var f = 'txt', ft = '';

        ft = fileType(msg.payload);
        if (ft) {
          f = ft.ext;
        }

        switch (f) {
        case 'wav':
        case 'flac':
        case 'ogg':
        case 'mp3':
        case 'mpeg':
          break;
        default:
          message = 'Audio format (' + f + ') not supported, must be encoded as WAV, MP3, FLAC or OGG.';
        }
      }
      if (message) {
        return Promise.reject(message);
      }
      return Promise.resolve();
    }

    function processInputBuffer(msg) {
      var p = new Promise(function resolver(resolve, reject){
        temp.open({suffix: '.' + fileType(msg.payload).ext}, function (err, info) {
          if (err) {
            reject(err);
          }
          payloadutils.stream_buffer(info.path, msg.payload, function (format) {
            var audioData = {},
              audio = fs.createReadStream(info.path);

            audioData.audio = audio;
            audioData.format = format;
            resolve(audioData);
          });
        });
      });
      return p;
    }

    function processInputURL(msg) {
      var p = new Promise(function resolver(resolve, reject){
        temp.open({suffix: '.audio'}, function(err, info){
          if (err) {
            reject(err);
          }
          payloadutils.stream_url(info.path, msg.payload, function (err, format) {
            if (err) {
              reject(err);
            }
            var audioData = {},
              audio = fs.createReadStream(info.path);

            audioData.audio = audio;
            audioData.format = format;
            resolve(audioData);
          });
        });
      });
      return p;
    }

    function processInput(msg) {
      // We are now ready to process the input data
      // If its a buffer then need to read it all before invoking the service
      if (msg.payload instanceof Buffer) {
        return processInputBuffer(msg);
      } else if (payloadutils.urlCheck(msg.payload)) {
        return processInputURL(msg);
      }
      return Promise.reject('Payload must be either an audio buffer or a string representing a url');
    }

    function performSTT(audioData) {
      var p = new Promise(function resolver(resolve, reject){
        var model = config.lang + '_' + config.band,
          params = {},
          speech_to_text = null,
          serviceSettings = {
            username: username,
            password: password,
            headers: {
              'User-Agent': pkg.name + '-' + pkg.version
            }
          };

        if (endpoint) {
          serviceSettings.url = endpoint;
        }

        speech_to_text = new sttV1(serviceSettings);

        // If we get to here then the audio is in one of the supported formats.
        if (audioData.format === 'ogg') {
          audioData.format += ';codecs=opus';
        }

        params = {
          audio: audioData.audio,
          content_type: 'audio/' + audioData.format,
          model: model,
          max_alternatives: config['alternatives'] ? parseInt(config['alternatives']) : 1,
          speaker_labels: config.speakerlabels ? config.speakerlabels : false,
          smart_formatting: config.smartformatting ? config.smartformatting : false
        };

        // Check the params for customisation options
        if (config.langcustom && 'NoCustomisationSetting' !== config.langcustom) {
          params.customization_id = config.langcustom;
        }

        // Everything is now in place to invoke the service
        speech_to_text.recognize(params, function (err, res) {
          if (err) {
            reject(err);
          } else {
            resolve(res);
          }
        });
      });
      return p;
    }

    function processResponse(msg, data) {
      var r = data.results;

      msg.transcription = '';
      if (r) {
        if (r.length && r[0].alternatives.length) {
          msg.fullresult = r;
        }
        msg.transcription = '';
        r.forEach(function(a){
          msg.transcription += a.alternatives[0].transcript;
          //a.alternatives.forEach(function(t){
          //  msg.transcription += t.transcript;
          //});
        });
      }
      if (config['payload-response']) {
        msg.payload = msg.transcription;
      }

      return Promise.resolve();
    }

    this.on('input', function (msg) {
      // Credentials are needed for the service. They will either be bound or
      // specified by the user in the dialog.
      username = sUsername || this.credentials.username;
      password = sPassword || this.credentials.password || config.password;

      endpoint = sEndpoint;
      if ((!config['default-endpoint']) && config['service-endpoint']) {
        endpoint = config['service-endpoint'];
      }

      node.status({});

      // Now perform checks on the input and parameters, to make sure that all
      // is in place before the service is invoked.
      initialCheck(username, password)
      .then(function(){
        return configCheck();
      })
      .then(function(){
        return payloadCheck(msg);
      })
      .then(function(){
        return processInput(msg);
      })
      .then(function(audioData){
        node.status({fill:'blue', shape:'dot', text:'requesting'});
        return performSTT(audioData);
      })
      .then(function(data){
        return processResponse(msg, data);
      })
      .then(function(){
        temp.cleanup();
        node.status({});
        node.send(msg);
      })
      .catch(function(err){
        temp.cleanup();
        payloadutils.reportError(node,msg,err);
      });

    });
  }

  RED.nodes.registerType('watson-speech-to-text', Node, {
    credentials: {
      username: {type:'text'},
      password: {type:'password'}
    }
  });
};
